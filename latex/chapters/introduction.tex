\chapter{Introduction}

The interest in the application fields of machine learning has a rising tendency nowadays. By using artificial intelligence, intelligent systems can be established which are able to solve real-world problems. As the computing capacity increases, there are enough resources to train more complex machine learning models and intelligent systems, such as deep artificial neural networks. Artificial neural networks are machine learning tools that allow the creation of intelligent systems. Python and its scientific third-party libraries are appropriate platforms that can create intelligent systems to facilitate machine learning tasks. However there is a subfield in connection with artificial neural networks, that has not received much attention since the rise of machine learning. This subfield is the problem of neural network inversion. The goal of the thesis is to solve this inversion problem. \medskip

This work belongs in the realm of machine learning application research. Three main tasks are being tackled in this paper: data mining for extracting information from the data set, building and testing multi-layer perceptron models, and the single element  inversion of the feedforward neural network.\medskip

Since preprocessing the data is a key factor to neural network performance, inversion can be implemented only after a sufficient neural network model has been established. Data mining is a tool for information extraction, processing, representation and summarization. It is designed to extract information from a dataset and transform it into a comprehensible structure for further use. The product of data mining is the preprocessed training set, whereat machine learning methods can be trained. \medskip

Machine learning is a field of artificial intelligence that gives computers the capability to learn from past data to help predict current or future states of a system. Learning relies on patterns and inferences, instead of explicit instructions. Machine learning utilizes statistical methods to process predefined datasets and to predict future output values for given data inputs. The used training methods originates from the application field of machine learning, more precisely from regression. \smallskip

Regression is a supervised learning task that adapts a function to a dataset to predict the values of a desired target variable. Since regression can fit a function to the training data in order to find the best fitting parameters, and the artificial neural networks can behave as a universal function approximator if there are infinite size of neurons available, neural networks can be used effectively to solve regression problems. Since there is no capacity for infinite number of neurons, the goal is to find that topology where the neural network is able to learn the regression function. Hence it is a long process to train a feedforward properly and find the best fitting regression function, but a necessary step to perform the inversion of the neural network. \medskip

The inverse function means the reverse of another function in mathematics. Neural network inversion means those procedures, that can approximate one or more points from the input set with respect of the examined output. Since feedforward neural networks aim on to capture system mapping from the given training data, the goal is to find those input values that will result the desired output for the given weights. The problem is that in case of a dataset, the output values are just rarely unique. Generally it can be determined that numerous inputs can generate the same output. Thus the neural networks are directly not invertible, but in case of a sufficient number of data with the assistance of a properly big topology, neural networks are able to estimate the inputs accurately for the examined output. In case of single element inversion methods, they are designed to find one point from the input space as opposed to evolutionary methods which are used to map multiple input points. \medskip

This work aims to implement and analyse the inversion of a single element feedforward neural network. The implementation that is being tackled in this paper suggests a solution for the inversion problem with the utilization of the Williams-Linder-Kindermann inversion. In the algorithm, the inversion problem is set up as an unconstrained optimization problem and solved by gradient descent, similarly to backpropagation.

